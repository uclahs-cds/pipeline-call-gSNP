import nextflow.util.SysHelper

// EXECUTION SETTINGS AND GLOBAL DEFAULTS
// Inputs/parameters of the pipeline
params {
     // sample inputs
    dataset_id = ''
    blcds_registered_dataset = false // if you want the output to be registered
    sge_scheduler = false // true

    input_csv = "/path/to/input.csv"

    // should the bams/gvcfs be processed per-chromosome?
    // List of chromosomes, defaults to hg38 canonical
    intervals = "${projectDir}/config/hg38_decoy_chromosomes_canonical.list"

    save_intermediate_files = false // true to save all intermediate files

    reference_fasta = "/path/to/genome/genome.fa"
    reference_dict = "/path/to/genome/genome.dict"

    bundle_v0_dbsnp138_vcf_gz = "/path/to/resources_broad_hg38_v0_Homo_sapiens_assembly38.dbsnp138.vcf.gz"

    bundle_mills_and_1000g_gold_standard_indels_vcf_gz = "/path/to/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz"

    bundle_known_indels_vcf_gz = "/path/to/Homo_sapiens_assembly38.known_indels.vcf.gz"

    bundle_v0_dbsnp138_vcf_gz = "/path/to/resources_broad_hg38_v0_Homo_sapiens_assembly38.dbsnp138.vcf.gz"

    bundle_hapmap_3p3_vcf_gz = "/path/to/hapmap_3.3.hg38.vcf.gz"

    bundle_omni_1000g_2p5_vcf_gz = "/path/to/1000G_omni2.5.hg38.vcf.gz"

    bundle_phase1_1000g_snps_high_conf_vcf_gz = "/path/to/1000G_phase1.snps.high_confidence.hg38.vcf.gz"

    bundle_contest_hapmap_3p3_vcf_gz = "/path/to/hapmap_3.3.hg38.BIALLELIC.PASS.vcf.gz"

    // input/output locations
    output_dir = "/path/to/outputs/"
    temp_dir = "/path/to/temp" // e.g /scratch

    // How many intervals to divide the genome into
    // If you run into memory issues, increase the scatter_count
    scatter_count = 50
    split_intervals_extra_args = ''

    // GenomicsDBImport parameters
    // Max number of intervals to import in parallel; higher values may improve performance, but require more memory and a higher number of file descriptors open at the same time
    max_num_intervals_to_import_in_parallel = 20
    // How many simultaneous threads to use when opening VCFs in batches; higher values may improve performance when network latency is an issue
    reader_threads = 10
    // Batch size controls the number of samples for which readers are open at once and therefore provides a way to minimize memory consumption
    // If batch_size > 100, use --consolidate True in extra args
    batch_size = 50 
    genomics_db_import_extra_args = ''

}

// External config files import
includeConfig "${projectDir}/config/methods.config"

// Metadata
manifest {
    name = 'regenotype-gSNP'
    author = 'Stefan Eng'
    description = 'Joint genotyping on a cohort.'
    version = '1.1.1'
}

def node_cpus = SysHelper.getAvailCpus()
def node_mem  = SysHelper.getAvailMemory().toString()

if (node_cpus == 2 && node_mem == '3 GB') {
    includeConfig "${projectDir}/config/lowmem.config"
} else if (node_cpus == 72 && node_mem == '136.8 GB') {
    includeConfig "${projectDir}/config/midmem.config"
} else if (node_cpus == 64 && node_mem == '950 GB') {
    includeConfig "${projectDir}/config/execute.config"
} else {
    throw new Exception('ERROR: System resources not as expected, unable to assign resources. Detected cpus: ${node_cpus} and memory: ${node_mem}')
}
